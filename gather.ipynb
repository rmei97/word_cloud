{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with removing stopwords and punctuations for any text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = stopwords.words('english')\n",
    "list_stopwords += list(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search data scientists positions\n",
    "<https://www.linkedin.com/jobs/search?keywords=Data%20Scientist&location=New%20York%2C%20NY&geoId=102690268&trk=public_jobs_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = 'https://www.linkedin.com/jobs/search?keywords=Data%20Scientist&location=New%20York%2C%20NY&geoId=102690268&trk=public_jobs_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0&f_TP=1%2C2%2C3%2C4'\n",
    "DRIVER_PATH = '/usr/local/bin/chromedriver'\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "driver.get(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-50e1a5199658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Wait to load page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCROLL_PAUSE_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Calculate new scroll height and compare with last scroll height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SCROLL_PAUSE_TIME = 4\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "#I need to count the number of clicks because there will be a point where I hit the \"See More\" button infinite times\n",
    "#I will use this variable and set the number of click to be a max of something as a condition\n",
    "click_counter = 0\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    #for now using 100 clicks because 99 * 15(jobs per page) < 1500 max number of jobs is less than 1500\n",
    "    if new_height == last_height & click_counter < 100: \n",
    "        try:\n",
    "            #use an XML path instead to get to the see more button\n",
    "            see_more = driver.find_elements_by_xpath('/html/body/main/div/section/button')\n",
    "            click_counter += 1\n",
    "            see_more[0].click()\n",
    "        except:\n",
    "            break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_search = BeautifulSoup(search_request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = soup_search.findAll('a', class_ = \"result-card__full-card-link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/view/marketing-data-scientist-at-google-2181386253?refId=ccd09f87-bf62-4ac8-a022-d37ee4f27970&position=1&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[0]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_response = requests.get(url = 'https://www.linkedin.com/jobs/view/2167608769')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_soup = BeautifulSoup(job_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember to use soup for \n",
    "a = soup.find('div', class_ = 'description__text description__text--rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: started with trying to use a scraper in Selenium to scroll for jobs, but I couldn't get the button to work perfectly. At this point going to just save the html to get the list of links for the jobs and in the future I can automate the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('jobs.html', 'r') as f:\n",
    "\n",
    "    contents = f.read()\n",
    "\n",
    "    search_soup = BeautifulSoup(contents, 'lxml')\n",
    "    jobs_list = search_soup.findAll('a', class_ = \"result-card__full-card-link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.linkedin.com/jobs/view/data-scientist-at-datadog-2209311577?refId=0cd06fc1-321c-4715-ace6-ec6a894ba73c&position=1&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-analytics-at-okcupid-2210722658?refId=0cd06fc1-321c-4715-ace6-ec6a894ba73c&position=2&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-at-ibm-2204969335?refId=0cd06fc1-321c-4715-ace6-ec6a894ba73c&position=3&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-advertising-business-at-spotify-2186338356?refId=0cd06fc1-321c-4715-ace6-ec6a894ba73c&position=4&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click',\n",
       " 'https://www.linkedin.com/jobs/view/data-scientist-analytics-at-facebook-2234723136?refId=0cd06fc1-321c-4715-ace6-ec6a894ba73c&position=5&pageNum=0&trk=public_jobs_job-result-card_result-card_full-click']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[job['href'] for job in jobs[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Top Card (about) </h2>\n",
    "\n",
    "    \n",
    "<t1>Individual page scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = job_soup.find('div',class_ = \"topcard__content-left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Scientist'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = temp.find('h1', class_ = \"topcard__title\").text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DURLSTON PARTNERS'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = temp.find('a', class_ = \"topcard__org-name-link topcard__flavor--black-link\").text\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York City Metropolitan Area'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = temp.find('span', class_ = \"topcard__flavor topcard__flavor--bullet\").text\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$100,000.00 - $140,000.00'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = temp.find('div',class_ = \"salary topcard__flavor--salary\").text\n",
    "salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A VC fund is looking to add a data scientist to their team. This person will perform data analysis and research on alternative data to drive insights and impact investment decisions.ResponsibilitiesApply data and analytical skills throughout the investment process to make significant contributions to research, idea generation, portfolio construction, performance analytics, and team workflowDevelop a strategic plan and roadmap for data research strategy and serve as an expert statistician/data scientist on an investment teamPerform analyses on large datasets to extract actionable insights that will help drive decisions across the businessCommunicate data-driven insights and recommendations to key stakeholdersRequirementsUndergraduate degree or higher in science, computer science, statistics, economics, mathematics, or similar quantitative disciplineStrong programming skills in SQL/NoSQL and at least one of the following Python, R, or C++Ability to balance strategic vision for the team with strong attention to detail and commercial awareness in a fast-paced environmentExperience working in Management Consulting is strongly desired'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = soup.find('div', class_ = \"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\").text\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requesting and getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/view/data-engineer-at-mount-sinai-covid-informatics-center-2149961964?refId=e30a4974-4ce8-406d-aa35-6d9b10ac9cf3&position=9&pageNum=11&trk=public_jobs_job-result-card_result-card_full-click'"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[278]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = requests.get(jobs[278]['href'], 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_soup = BeautifulSoup(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = posting_soup.find('div', class_ = \"show-more-less-html__markup show-more-less-html__markup--clamp-after-5\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strength Through Diversity Ground breaking science. Advancing medicine. Healing made personal. \\xa0 The Mount Sinai COVID Informatics Center (MSCIC) aims to translate and unify data from the Mount Sinai Health System (MSHS) into actionable information and insights that can be mobilized against COVID-19 and ensure that MSHS is ready for similar public health threats in the future. \\xa0 MSCIC is hiring a centralized Engineering Core that will build an Informatics Crisis Response Platform. This platform will include two components: (1) a Critical Informatics Consultation Service that provides MSHS clinicians and researchers easy-to-digest answers to pressing clinical questions (2) a Rapid Clinical Intervention Toolkit that facilitates the practice of evidence-based medicine in the MSHS by feeding insights from data science into the daily workflow via the electronic medical record. \\xa0 Who we are looking for: MSCIC is looking to hire experienced data engineers who will help build the platform that will enable informaticists, researchers, and clinicians to collaborate in a common environment, bring data into clinical settings in novel ways, and provide practitioners with more information when making diagnoses and treatment plans.  Role\\xa0& Responsibilities: The Senior Data Engineer (Data Ingestion) will primarily be responsible for ingesting and staging data from various groups across the Mount Sinai Health System (MSHS). They’ll lead the relationships with these groups to manage upstream data sources, develop strategies, and build software for ingesting these data into the Critical Informatics Consult Repository. The Senior Data Engineer will have the opportunity to: · \\xa0 \\xa0 \\xa0 \\xa0 facilitate collaboration between MSCIC and other groups in the organization · \\xa0 \\xa0 \\xa0 \\xa0 curate valuable datasets in the Consult Repository, which includes ingestion, documentation, and building subject matter expertise · \\xa0 \\xa0 \\xa0 \\xa0 coordinate data strategies with external teams and communicate them back to the engineering team · \\xa0 \\xa0 \\xa0 \\xa0 gain a wide understanding of the many systems throughout the MSHS · \\xa0 \\xa0 \\xa0 \\xa0 work with data in multiple formats (eg. structured, imaging, genetic) · \\xa0 \\xa0 \\xa0 \\xa0 ingest data from a wide range of data platforms, platforms, and sources · \\xa0 \\xa0 \\xa0 \\xa0 become a steward of data many data that impact patient care \\xa0 Requirements Ideal candidates will have 5+ years technical experience – preferably in industry - including competencies in the following: · \\xa0 \\xa0 \\xa0 \\xa0 extremely strong SQL and RDBMS · \\xa0 \\xa0 \\xa0 \\xa0 clinical medicine, clinical vocabulary preferred · \\xa0 \\xa0 \\xa0 \\xa0 ETL/ELT · \\xa0 \\xa0 \\xa0 \\xa0 development of reproducible and reliable data pipelines, using both vendor tools and custom-written software · \\xa0 \\xa0 \\xa0 \\xa0 Working with highly sensitive and regulated Protected Health Information (PHI), and navigating related regulations/rules · \\xa0 \\xa0 \\xa0 \\xa0 experience in formal QA/QC environments · \\xa0 \\xa0 \\xa0 \\xa0 written production software in compiled languages (Java, Scala, Haskell, Go). · \\xa0 \\xa0 \\xa0 \\xa0 written production software in interpreted languages (Python, Ruby, Perl, or PHP) · \\xa0 \\xa0 \\xa0 \\xa0 code repository platforms such as Git, Subversion, Mercurial, etc. · \\xa0 \\xa0 \\xa0 \\xa0 cloud infrastructure administration in Azure, AWS, or Google Cloud · \\xa0 \\xa0 \\xa0 \\xa0 Hadoop, Spark, or similar big data environments   \\xa0  Strength Through Diversity  \\xa0  The Mount Sinai Health System believes that diversity and inclusion is a driver for excellence. We share a common devotion to delivering exceptional patient care. Yet we are as diverse as the city we call home- culturally, ethically, in outlook and lifestyle. When you join us, you become a part of Mount Sinai’s unrivaled record of achievement, education and advancement as we revolutionize healthcare delivery together.  \\xa0  We work hard to recruit and retain the best people, and to create a welcoming, nurturing work environment where you have the opportunity and support to develop professionally. We share the belief that all employees, regardless of job title or expertise, have an impact on quality patient care.  \\xa0  Explore more about this opportunity and how you can help us write a new chapter in our story!  \\xa0  Who We Are  \\xa0  Over 38,000 employees strong, the mission of the Mount Sinai Health System is to provide compassionate patient care with seamless coordination and to advance medicine through unrivaled education, research, and outreach in the many diverse communities we serve.  \\xa0  Formed in September 2013, The Mount Sinai Health System combines the excellence of the Icahn School of Medicine at Mount Sinai with seven premier hospitals, including Mount Sinai Beth Israel, Mount Sinai Brooklyn, The Mount Sinai Hospital, Mount Sinai Queens, Mount Sinai West (formerly Mount Sinai Roosevelt), Mount Sinai Morningside and New York Eye and Ear Infirmary of Mount Sinai.  \\xa0  The Mount Sinai Health System is an equal opportunity employer. We comply with applicable Federal civil rights laws and does not discriminate, exclude, or treat people differently on the basis of race, color, national origin, age, religion, disability, sex, sexual orientation, gender identity, or gender expression.  \\xa0  EOE Minorities/Women/Disabled/Veterans  \\xa0 \\xa0'"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Engineer'"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\ttitle = posting_soup.find('h1', class_ = \"topcard__title\").text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-523-0129fc99fbee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposting_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"topcard__org-name-link topcard__flavor--black-link\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcompany\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "\tcompany = posting_soup.find('a', class_ = \"topcard__org-name-link topcard__flavor--black-link\").text\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York, NY'"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\tlocation = posting_soup.find('span', class_ = \"topcard__flavor topcard__flavor--bullet\").text\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The digital currency market is the most exciting and fastest-growing segment of finance, with new institutions and capital from around the world entering the space every day. Genesis Global Trading, a subsidiary of Digital Currency Group, is a pioneer in the industry, launching the first digital asset trading desk in 2013 and the first institutional lending business in 2018. Today, Genesis sits at the forefront of the industry as a global leader, providing digital asset trading, lending, custody and prime brokerage services.Genesis Trading is seeking a talented Quantitative Researcher to develop statistical and mathematical trading algorithms for digital currency markets. Quantitative Researchers at Genesis work closely as a team to find statistically significant signals in noisy markets and deploy them to our high-frequency trading engine. The Quantitative Researcher will have a solid foundation in mathematics and a deep understanding of how to apply predictive models in an uncertain world. The ideal candidate will have a willingness to write efficient code to test hypotheses.Primary Responsibilities  Collaborate with other researchers and traders to develop and optimize statistical signals Implement and deploy algorithmic trading strategies Analyze metrics related to live models and formulate strategies to improve said metrics Requirements  Advanced education (B.S., M.S., PhD) in mathematics, statistics, computer science, or related quantitative field  Experience in applying predictive and data-mining algorithms to large datasets  Strong proficiency in at least one programming language (like Python, Java, Golang, C++)  Experience with relational and time-series databases  Practical experience in deploying large-scale machine learning models is a plus, including knowledge of ML frameworks such as Tensorflow, Pytorch, Keras, etc. Personal AttributesStrong interpersonal and communication skills  Self-starter yet knows when to ask for help and works great in a team  Strives to simultaneously achieve high-velocity and high-quality output  Willingness and ability to meet aggressive deadlines  Thrives in a dynamic and high-pressured environment  Proven troubleshooting and problem-solving skills Benefits Comprehensive health, vision, dental and FSA benefits Flexible time offShow moreShow less'"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posting_soup.find('div', class_ = 'description__text description__text--rich').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"index\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-2bebacf2eabd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"CREATE TABLE listings (index INTEGER, title TEXT NOT NULL, company TEXT NOT NULL, location TEXT NOT NULL, description TEXT NOT NULL)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m: near \"index\": syntax error"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('jobs.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "query = \"\"\"CREATE TABLE listings (index INTEGER, title TEXT NOT NULL, company TEXT NOT NULL, location TEXT NOT NULL, description TEXT NOT NULL)\"\"\"\n",
    "c.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db():\n",
    "    conn = sqlite3.connect('jobs.db')\n",
    "    c = conn.cursor()\n",
    "    try:\n",
    "        query = \"\"\"CREATE TABLE listings (index INTEGER PRIMARY KEY, title TEXT NOT NULL, company TEXT NOT NULL, location TEXT NOT NULL, description TEXT NOT NULL)\"\"\"\n",
    "        c.execute(query)\n",
    "    except: #trying to catch OperationalError but will commit a sin of except pass:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "connect_to_db\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sqlite3.connect('test.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_c = test.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1a22af9b90>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"CREATE TABLE if not exists listings (num INTEGER PRIMARY KEY, title TEXT NOT NULL, company TEXT NOT NULL, location TEXT NOT NULL, description TEXT NOT NULL)\"\"\"\n",
    "c.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'test']"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(table):\n",
    "    try:\n",
    "        conn = sqlite3.connect(table)\n",
    "        c = conn.cursor()\n",
    "        query = \"\"\"CREATE TABLE listings (index INTEGER PRIMARY KEY, title TEXT NOT NULL, company TEXT NOT NULL, location TEXT NOT NULL, description TEXT NOT NULL)\"\"\"\n",
    "        c.execute(query)\n",
    "    except OperationalError as e:\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"\"\"SELECT * FROM listings\"\"\")\n",
    "rows = c.fetchall()\n",
    "\n",
    "for row in rows[:5]:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['test1','test2','test3','test4']\n",
    "data2 = ['test5','test6','test7','test8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1a23a9b9d0>"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"\"\"INSERT INTO listings VALUES(?,?,?,?)\"\"\", data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1a23a9b9d0>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(\"\"\"SELECT * FROM listings\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_table(table_name):\n",
    "    conn = sqlite3.connect('test.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"\"\"SELECT * FROM {};\"\"\".format(table_name))\n",
    "    \n",
    "    rows = c.fetchall()\n",
    "    for row in rows[:5]:\n",
    "        print(row)\n",
    "        \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_table('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('test.db')\n",
    "conn.execute(\"CREATE TABLE IF NOT EXISTS test2 (id INT, words TEXT)\")\n",
    "conn.execute(\"INSERT INTO test2 VALUES (?,?)\", [10,'words'])\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 'words')\n"
     ]
    }
   ],
   "source": [
    "view_table('test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-566-1ace21c6aaac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "rows = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
